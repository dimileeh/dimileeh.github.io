---
layout: post
title:  "The Dawn of the Human-Like Artificial Intelligence"
categories: ai
tags: machine learning, deep learning, artificial intelligence, DeepMind
comments: true
---
The vast majority of modern computers follow the von Neumann architecture in terms of having a processing unit and memory that holds the data and instructions. Unlike neural networks that are trained to perform various tasks, conventional computers have to be programmed, in other words, they have to be told what to do in each and every scenario. In October 2016, [DeepMind](http://www.deepmind.com) published a paper [“Hybrid computing using a neural network with dynamic external memory” by A. Graves et al.](https://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz) and introduced a differentiable neural computer (DNC) – something that can be considered as a mix between deep neural networks and a computer. Such combination resulted in a powerful synergy of "learning and pattern recognition with the ability to store complex computational graphs in an external memory". The term “differentiable” refers to the fact that in addition to differentiable activation functions of the neural networks that allow backpropagation and training, DNC memory interactions are also differentiable end-to-end allowing to optimize them using gradient descent. In other words, a DNC represents an attempt to teach computers to learn, reason and build logical constructions.

While the results presented in the paper may not seem outstanding – all of them could be achieved with conventional computer decades ago – what is more important to appreciate is the fact that unlike traditional computers, the DNC was able to accomplish these results following the human-like reasoning.

DeepMind scientists conducted three types of experiments to test the capabilities of the DNC in comparison with an LSTM neural network. Synthetic question answering test was designed to mimic textual reasoning. For example, given such statements as “Mary is in the garden. Mary picked up a flower.”, followed by a question, “Where is the flower?”, the DNC can combine two supporting facts and produce a correct answer “garden”. In the graph experiments, DNC was trained on the London Underground map to search for an optimal way to get from one station to another. Also, given a family tree, the DNC was able to answer relationship questions like “Who is Simon’s maternal great uncle?”.

Unlike the previous two types of experiments that used supervised learning to train the network, block puzzle experiment applied a form of reinforcement learning. A sequence of instructions describing a goal was coupled to a reward function. The purpose of this experiment was to investigate DNC’s ability to utilise their memory for logical planning tasks. The block puzzle game is a classical artificial intelligence demonstration of an environment with movable objects and a list of instructions to be performed. The DNC iteratively wrote goals into the memory to store the instructions, thus being then able to carry out any chosen goal. Remarkably, the DNC learned to write its decisions to memory before taking any action upon them indicating that it learned to make a plan.

In all three types of experiments, the DNC by far outperformed the best LSTM networks. For example, in the graph experiment, LSTM achieved only 37% accuracy compared with an average of 98.8% obtained by the DNC. In the block puzzle game, an LSTM network was not able to complete even half of the training, compared with the DNC that finished the learning curriculum.

Just like conventional computers have a CPU and RAM, a DNC has a neural network that represents a computational unit and dynamic external memory. The dawn of human-like intelligent machines that will be able to solve tasks ranging from game playing to strategic reasoning has begun.
